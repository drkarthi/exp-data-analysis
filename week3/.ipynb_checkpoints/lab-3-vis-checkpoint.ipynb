{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 370 - Lab Session 3: Vis Basics\n",
    "## Objectives:\n",
    "1. Practice creating various plots for nominal, ordinal, and quantitative data using `matplotlib`, `pandas`, and `seaborn`.\n",
    "3. Understand the limitation of built-in plotting functionality of `pandas` and when to switch to `matplotlib` and when to use `seaborn`.\n",
    "4. Understand the existance of outliers and how to detect and remove outliers (left-over topic from the last week).\n",
    "\n",
    "## What to do\n",
    "1. Download the `.ipynb` file of this notebook.\n",
    "2. Follow this notebook step-by-step. Execute every cell and verify the result as you go.\n",
    "3. Do the exercises as instructed and fill in the answers on the lab worksheet.\n",
    "<br><span style=\"color:red\">When you are doing the exercises, do not edit existing cells. __Insert new cells__ below the exercise questions, and type or copy over the code into the new cells.</span>\n",
    "5. Take notes by adding Markdown cells or add comments to existing code. Keep this notebook for future reference.\n",
    "6. Turn in the worksheet before you leave. Use the [online version of the worksheet](https://drive.google.com/open?id=1DtbBEKTwxE2Ji8IrCQZjP6jmgRazhhMcHCHa6t0TM6k) for after-class study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Seaborn\n",
    "`Seaborn` is a python package built on top of `matplotlib`, that provides additional (awesome) style management and a variety of convenient plotting functions. It can also work closely with `DataFrames` of `pandas`.\n",
    "\n",
    "Before everything, install `seaborn` in your `Anaconda` environment.\n",
    "\n",
    "In `Terminal` (or `Command Prompt` in Windows), type in the following command, just as if you would install any other package.\n",
    "        \n",
    "        conda install seaborn\n",
    "or\n",
    "        \n",
    "        conda install --name=python3 seaborn\n",
    "\n",
    "When you are done, come back to this IPython notebook. The rest of the lab will be done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First things first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's first plot something using matplotlib's default style\n",
    "data = np.random.randn(2, 100)  # Generate 100 random points in 2-D space\n",
    "plt.scatter(data[0], data[1], color='b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">If you get an import error in the following cell, you can restart the IPython kernel by going to the menu at the top and select: Kernel -> Restart and click on the \"Restart\" button.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's import seaborn\n",
    "# See how it beautifies the style automatically?\n",
    "# If you get an error executing this cell, see the red note above.\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(data[0], data[1], color='b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the plot with the same data looks much nicer now?\n",
    "\n",
    "In the second line of the above cell, the option `color_codes=True` allows seaborn to automatically change the interpretation of shorthand codes like \"r\" (red) or \"b\" (blue) by matplotlib in subsequent plots. This will result in more \"pretty\" colors aesthetically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Import Data\n",
    "For this lab, we will use the movies dataset. \n",
    "\n",
    "__Download the movies dataset from CTools:__\n",
    "\n",
    "- Use [this link](https://ctools.umich.edu/access/content/group/09aeadb1-5ac1-4433-9741-033966380c8a/Datasets/movies.csv) or go to `CTools -> SI 370 -> Resource -> Datasets -> movies.csv` to download the dataset. Once downloaded, put it in the same folder with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv('movies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look at its shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some cleaning - You don't need to know the details here.\n",
    "\n",
    "# 1. string to number (some \"Unknowns\" in these columns\n",
    "#    will be replaced with NaN)\n",
    "cols = ['US Gross', 'Worldwide Gross']\n",
    "df[cols] = df[cols].convert_objects(convert_numeric=True)\n",
    "\n",
    "# 2. string to datetime (some cells with different formats \n",
    "#    will be replaced with NAT)\n",
    "rdate = pd.to_datetime(df['Release Date'], format='%d-%b-%y', coerce=True)\n",
    "rdate[rdate > '2015-01-01'] -=  np.timedelta64(100, 'Y')\n",
    "df['Release Date'] = rdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take another look at its shape.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing 2D Quantitative Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize Rotten Tomato vs. IMDB Rating\n",
    "# There are three solutions: Pandas, Matplotlib, and Seaborn.\n",
    "# Solution 1: Pandas\n",
    "df.plot(x='Rotten Tomatoes Rating', y='IMDB Rating', kind='scatter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution 2: matplotlib\n",
    "# In Matplotlib, we have to manually specify the xlabel and ylabel.\n",
    "# However, plotting this way gives us more flexibility and control.\n",
    "plt.scatter(x=df['Rotten Tomatoes Rating'], y=df['IMDB Rating'])\n",
    "plt.xlabel('Rotten Tomatoes Rating')\n",
    "plt.ylabel('IMDB Rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution 3: using Seaborn\n",
    "# Note: regplot means \"Regression Plot\". \n",
    "# Setting fit_reg=False means we don't want a regression line.\n",
    "sns.regplot('Rotten Tomatoes Rating', 'IMDB Rating', data=df, \n",
    "            fit_reg=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seaborn, it is also convenient to leverage the color (_hue_) channel to have additional encoding of __nominal data__ in the scatter plot. See the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding \"hue\" to the scatter plot.\n",
    "# This is a slightly different function:\n",
    "#   lmplot means \"linear model plot\".\n",
    "# Note that we have to filter the distributors, \n",
    "# otherwise we would end up with too many colors.\n",
    "few_distributors = ['Universal', 'Walt Disney Pictures', 'MGM']\n",
    "df_few_distributors = df[df['Distributor'].isin(few_distributors)]\n",
    "sns.lmplot('Rotten Tomatoes Rating', 'IMDB Rating', \n",
    "           data=df_few_distributors,\n",
    "           hue='Distributor', fit_reg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Another example scatter plot, depicting gross vs budget per film.\n",
    "few_genres = ['Drama','Adventure','Comedy']\n",
    "df_few_genres = df[df['Major Genre'].isin(few_genres)]\n",
    "\n",
    "# We grab the returned value of lmplot so that we can alter the plotted\n",
    "# figure later on.\n",
    "grid = sns.lmplot('Production Budget', 'Worldwide Gross',\n",
    "                  data=df_few_genres, hue='Major Genre', fit_reg=False)\n",
    "\n",
    "# We alter the axes of the figure to use a log-log scale.\n",
    "# This helps us see the distributor of the points better.\n",
    "# Try plotting the same figure with and without the following line.\n",
    "grid.set(xscale=\"log\", yscale=\"log\", xlim=(1e4,1e9), ylim=(1e5, 2e9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. Create a scatter plot of `IMDB Rating` vs. `Wordwide Gross`.\n",
    "2. Add `hue=\"MPAA Rating\"` to the scatter plot. Limit to `R, PG-13, and G` only.\n",
    "3. Answer the questions in __Worksheet Problem 1__ by reading the scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Line Chart\n",
    "Commonly used to visualize a trend in data over time; thus one of the variables should be time or a time-like measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's simulate a \"random walk\".\n",
    "# Run this cell multiple times. Each time, you will get a different result.\n",
    "\n",
    "# Each step: we flip a coin, making a decision to either move forward (+1), backward (-1), or stay (0)\n",
    "decisions = np.random.randint(-1, 2, 1000)\n",
    "\n",
    "# Using np.cumsum() we can conveniently calculate \"where we are now\".\n",
    "locations = np.cumsum(decisions)\n",
    "\n",
    "# Visualize the locations over time (or steps)\n",
    "# The semicolon is to suppress return of the plot function\n",
    "plt.plot(locations);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can repeat the above random walk multiple times, and overlay the results together\n",
    "for i in range(10):\n",
    "    decisions = np.random.randint(-1, 2, 1000)\n",
    "    locations = np.cumsum(decisions)\n",
    "    plt.plot(locations, label='Walk %d'%i)\n",
    "\n",
    "# This line alters the legend location.\n",
    "# Otherwise the legend would endup overlap with the lines.\n",
    "plt.legend(loc='center right', bbox_to_anchor=(1.2, 0.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the trend of the average movie budget over years.\n",
    "\n",
    "# Step 1: prepare the data.\n",
    "# Note: the first line extracts years from release dates.\n",
    "years = pd.DatetimeIndex(df['Release Date']).year\n",
    "by_year = df.groupby(years)\n",
    "budget_mean_by_year = by_year[['Production Budget']].mean()\n",
    "\n",
    "# Step 2: Make the plot\n",
    "budget_mean_by_year.plot()\n",
    "\n",
    "# Step 3: Limit the x-axis range\n",
    "plt.xlim(1950, 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. Create a line chart depicting the trend of worldwide gross over years.\n",
    "2. Limit the range on x-axis to be `(1950, 2010)`.\n",
    "3. Answer the question in __Worksheet Problem 2__ using the chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing 2D  Data (1 Nominal + 1 Quan.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using pandas to create a bar plot\n",
    "by_distributor = df.groupby('Distributor')\n",
    "mean_gross = by_distributor[['Worldwide Gross']].mean()\n",
    "top_mean_gross = mean_gross.sort('Worldwide Gross', ascending=False).head(10)\n",
    "top_mean_gross.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use seaborn to create a bar plot of mean value with confidence intervals\n",
    "sns.barplot(x='MPAA Rating', y='Worldwide Gross', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding a hue channel to the bar plot\n",
    "# Compare two distributors only\n",
    "df_universal_disney = df[df.Distributor.isin(('Universal', 'Walt Disney Pictures'))]\n",
    "sns.barplot(x='MPAA Rating', y='Worldwide Gross', \n",
    "            data=df_universal_disney,\n",
    "            hue='Distributor');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a box plot, using the same data as above\n",
    "sns.boxplot(x='MPAA Rating', y='Worldwide Gross', \n",
    "            data=df_universal_disney,\n",
    "            hue='Distributor');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. Create a __bar plot__ comparing the __mean production budget__ of films by `20th Century Fox, Universal, Walt Disney Pictures`.\n",
    "2. Add `hue='Major Genre'` to the bar plot. Limiting to `Drama`, `Adventure`, and `Thriller/Suspense` only.\n",
    "3. Create a __box plot__ of the same data.\n",
    "4. Answer the questions in __Worksheet Problem 3__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacked Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A simple example of stacked bar charts.\n",
    "df_toy = pd.DataFrame({'A':[1,2,3], 'B':[2,3,1]}, index=list('xyz'))\n",
    "df_toy.plot(kind='bar', stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A more complex example or stacked bar charts. \n",
    "# Comparing the average contribution of each genre to the world-wide gross by distributor \n",
    "# over the years of 1991-2010.\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "years = pd.DatetimeIndex(df['Release Date']).year\n",
    "df_in_years = df[(years >= 1991) & (years <= 2010)]\n",
    "top_dstr = ['Summit Entertainment', '20th Century Fox', \n",
    "                    'Warner Bros.', 'Walt Disney Pictures', \n",
    "                    'Dreamworks SKG', 'Paramount Pictures',  \n",
    "                    'Universal', 'Sony Pictures']\n",
    "df_top_dstr = df_in_years[df_in_years.Distributor.isin(top_dstr)]\n",
    "df_genre_pivot = df_top_dstr.pivot_table(\n",
    "                    values='Worldwide Gross', columns='Major Genre', \n",
    "                    index='Distributor', aggfunc=np.mean)\n",
    "\n",
    "# Step 2: Make the plot\n",
    "df_genre_pivot.plot(kind='barh', stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a custom palette to avoid repeating the colors.\n",
    "with sns.hls_palette(12):\n",
    "    df_genre_pivot.plot(kind='barh', stacked=True);\n",
    "\n",
    "# Add a label to the x-axis\n",
    "plt.xlabel('Mean Worldwide Gross');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. Create a stacked bar chart, comparing the __Total Production Budget__ of the films by top distributors over the years of 1991-2010. Using __MPAA Rating__ as hue. <br>_Hint_: You may reuse `df_top_dstr` create above. Start with creating a pivot_table.\n",
    "2. Answer the questions in __Worksheet Problem 4__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Histogram and Kernel Density Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a histogram using Pandas\n",
    "df['IMDB Rating'].plot(kind='hist', bins=20, title='IMDB Rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a histogram using seaborn with kernel density estimation (KDE)\n",
    "sns.distplot(df['IMDB Rating'].dropna(), kde=True, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. Create a histogram of Rotten Tomatoes Rating for all films.\n",
    "2. Add KDE to the above histogram.\n",
    "3. Answer the question in __Worksheet Problem 5__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scatter Plot Matrix (SPLOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SPLOM example\n",
    "# This function needs a clean DataFrame.\n",
    "df_cleaned = df[['Worldwide Gross','Production Budget','IMDB Rating',\n",
    "                 'MPAA Rating']].dropna()\n",
    "sns.pairplot(df_cleaned);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with hue\n",
    "sns.pairplot(df_cleaned, hue='MPAA Rating');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. __[Code Provided]__ Create a new DataFrame with only Warner Bros. and Sony Pictures.\n",
    "2. Use to the DataFrame to create a SPLOM, visualizing the relations between `Wordwide Gross, Production Budget, IMDB Rating`, and `Rotten Tomatoes Rating`, using __Distributor__ as hue.\n",
    "3. Answer the question in __Worksheet Problem 6.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1. (Code Provided)\n",
    "df_two_dstr = df[df.Distributor.isin(('Warner Bros.', 'Sony Pictures'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scatter Plot with Fitted Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot with a linear fitted line.\n",
    "sns.regplot(x='Rotten Tomatoes Rating', y='IMDB Rating', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Another example with a linear fit -- with the Anscombe's Quartet data\n",
    "df_ans = sns.load_dataset(\"anscombe\")\n",
    "df_ans2 = df_ans.loc[df_ans.dataset == \"II\"]\n",
    "sns.regplot(x=\"x\", y=\"y\", data=df_ans2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit a higher-order polynomial regression\n",
    "sns.regplot(x=\"x\", y=\"y\", data=df_ans2, order=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's plot them side-by-side\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(12,5), sharey=True)\n",
    "sns.regplot(x=\"x\", y=\"y\", data=df_ans2, \n",
    "            ax=axes[0], scatter_kws={\"s\": 100})\n",
    "sns.regplot(x=\"x\", y=\"y\", data=df_ans2, order=2, \n",
    "            ax=axes[1], scatter_kws={\"s\": 100});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. __[Code Provided]__ Get the Anscombe's Dataset III. \n",
    "2. Create two regression plots side-by-side, with linear and 2nd order fitted lines respectively.\n",
    "3. There is no worksheet question for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1. [Code Provided] Get Ansombe's dataset III\n",
    "df_ans3 = df_ans[df_ans.dataset=='III']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Scatter Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot with marginal histograms.\n",
    "sns.jointplot(x='Rotten Tomatoes Rating', y='IMDB Rating', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add regresion lines\n",
    "sns.jointplot(x='Rotten Tomatoes Rating', y='IMDB Rating', \n",
    "              data=df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "1. Create a scatterplot with marginal histograms with regression lines for Worldwide Gross vs. Production Budget.\n",
    "2. There is no worksheet problem for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "What we have learned so far:\n",
    "- Seaborn is a package that provides professional-looking style and various convenient plotting functions.\n",
    "- Adding `hue` to seaborn plots is a convenient way of encoding an extra nominal data dimension in the visualization.\n",
    "  - In practice, we may need to do grouping and filtering to reduce the amount of information encoded in the `hue` channel.\n",
    "- In order to produce complex visualizations, we sometimes need to go through multiple steps of data filtering and aggregation. Often, the [split-apply-combine routine](http://pandas.pydata.org/pandas-docs/stable/groupby.html) is necessary. To perform this routine, we may use `pivot_table()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Outlier Detection and Removal\n",
    "This is a left-over topic from the last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the Anscombe's Quartet again.\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 7))\n",
    "rome_nums = ['I','II','III','IV']\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    j = i + 1\n",
    "    df_i = df_ans[df_ans.dataset==rome_nums[i]]\n",
    "    df_i.plot('x', 'y', kind='scatter', ax=ax)\n",
    "    ax.set_xlabel('X%d'%j)\n",
    "    ax.set_ylabel('Y%d'%j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "df_ans3 = df_ans[['x','y']][df_ans.dataset == 'III'].reset_index(drop=True)\n",
    "df_ans4 = df_ans[['x','y']][df_ans.dataset == 'IV'].reset_index(drop=True)\n",
    "model1 = smf.ols('y ~ x', data=df_ans3).fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Background Knowledge on Outlier Detection\n",
    "We will use the following influence statistics for detecting outliers.\n",
    "- __Cook's distance (`cooks_d`)__: measures the distance between the fitted values (Y) calculated with and without a given observation point.\n",
    "- __DFFTIS (`dffits`)__: same as Cook's distance, except the distance is measured by the approximate number of standard deviations.\n",
    "\n",
    "* * * \n",
    "\n",
    "In practice, the following __empirical cut-off thresholds__ may be used to identify outliers or leverage points. Let us define n as the number of observations, and p as the number of parameters.\n",
    "- __Cook's distance__: 4/n, or simply, 1. Observation points whose Cook's distance is greater than this threshold are considered as influential points.\n",
    "- __DFFITS__: 2 * sqrt(p/n). Observation points whose absolute DFFITS values are greater than  this threshold are considered influential points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find outliers using Cook's Distance\n",
    "influence = model1.get_influence()\n",
    "cooks_distance = influence.cooks_distance[0]\n",
    "number_of_observations = len(df_ans3)\n",
    "\n",
    "# Use an empirical threshold value\n",
    "cooks_threshold = 4 / number_of_observations\n",
    "\n",
    "# Show outliers\n",
    "df_ans3[cooks_distance > cooks_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize Cook's Distance\n",
    "# It is very obvious which data point is an outlier.\n",
    "plt.stem(cooks_distance);\n",
    "plt.xticks(range(len(df_ans3)));\n",
    "plt.ylim(0, 1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find outliers using DFFITS\n",
    "number_of_observations = len(df_ans3)\n",
    "number_of_parameters = 2  # parameters include: intercept, x\n",
    "dffits = influence.dffits[0]\n",
    "\n",
    "# Use an empirical threshold\n",
    "dffits_threshold = 2 * np.sqrt(number_of_parameters / number_of_observations)\n",
    "df_ans3[np.abs(dffits) > dffits_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize DFFITS (absolute value)\n",
    "plt.stem(np.abs(dffits));\n",
    "plt.xticks(range(len(df_ans3)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "# using Cook's Distance\n",
    "outlier_criterion = (cooks_distance > cooks_threshold)\n",
    "outlier_indexes = np.nonzero(outlier_criterion)[0]\n",
    "\n",
    "df_ans3_cleaned = df_ans3[~outlier_criterion]\n",
    "print(\"%d points before removal; %d after removal.\"%(\n",
    "        len(df_ans3), len(df_ans3_cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a new model with outliers removed\n",
    "model2 = smf.ols('y ~ x', data=df_ans3_cleaned).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are interested in how much the R-squared has improved.\n",
    "print('Before outlier removal, R^2 = %f'%(model1.rsquared_adj))\n",
    "print('After outlier removal, R^2 = %f'%(model2.rsquared_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the old and new regression lines together\n",
    "xs = np.linspace(3, 15, 2)\n",
    "ys1 = model1.predict({'x': xs})\n",
    "ys2 = model2.predict({'x': xs})\n",
    "plt.scatter(df_ans3_cleaned.x, df_ans3_cleaned.y, \n",
    "            s=100, marker='v')\n",
    "plt.scatter(df_ans3.ix[outlier_indexes, 'x'], \n",
    "            df_ans3.ix[outlier_indexes, 'y'], \n",
    "            s=100, color='r', marker='v')\n",
    "plt.plot(xs, ys1, 'r--', label='Before outlier removal')\n",
    "plt.plot(xs, ys2, 'k', label='After outlier removal')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('X3')\n",
    "plt.ylabel('Y3')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "- Step 1: __[Code Provided]__ Generate a toy dataset with X, Y\n",
    "- Step 2: __[Code Provided]__ Create a scatter plot of (X, Y)\n",
    "- Step 3: Build a linear regression model for Y ~ X\n",
    "- Step 4: Identify outliers using Cook's distance and DFFITS\n",
    "- Step 5: Remove outliers and plot a new regression line\n",
    "- Step 6: Fill in the blanks in the __Worksheet Problem 7.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1. [CODE PROVIDED] Generate a toy dataset\n",
    "np.random.seed(0)\n",
    "X = np.arange(23)\n",
    "Y = X * 2 + 3 + np.random.randn(len(X))\n",
    "\n",
    "# Add artificial outliers\n",
    "X = np.insert(X, 5, 10)\n",
    "Y = np.insert(Y, 5, 55)\n",
    "X = np.insert(X, 10, 3)\n",
    "Y = np.insert(Y, 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2. [CODE PROVIDED] Scatter plot of X and Y\n",
    "plt.scatter(X, Y, s=50);\n",
    "plt.xlabel('X');\n",
    "plt.ylabel('Y');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
